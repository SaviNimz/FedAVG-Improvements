
This project enhances the Federated Averaging (FedAvg) algorithm with a lightweight knowledge distillation regularizer to reduce client drift and improve global model accuracy on non-IID data.
